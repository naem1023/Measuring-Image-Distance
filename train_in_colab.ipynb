{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "train_in_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Njx8KARvVQd1"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8147facf455a4ef0abc520b53421ea31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_45ec6d6ea6bc43acb3dad166b046aed9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f5bc69776dee47a4a2c2b3cfce2a7519",
              "IPY_MODEL_35e8a20e4a1141cdbebc6c6ebb513892"
            ]
          }
        },
        "45ec6d6ea6bc43acb3dad166b046aed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5bc69776dee47a4a2c2b3cfce2a7519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3b325efb1bb34364b672a5c4e0a7d98d",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 60907,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6baab9ebb6344bb59eba1fab015ef8a2"
          }
        },
        "35e8a20e4a1141cdbebc6c6ebb513892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab04ed14d9204dd1a4d41f643880d777",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/60907 [00:43&lt;134:54:24,  7.97s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_068cb2b7963b49dc9ec3edb9bc2bc365"
          }
        },
        "3b325efb1bb34364b672a5c4e0a7d98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6baab9ebb6344bb59eba1fab015ef8a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab04ed14d9204dd1a4d41f643880d777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "068cb2b7963b49dc9ec3edb9bc2bc365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3652d9ff48f4ba88c2f5ef5eef6e7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a323264e30b44396a15b47a2c52f13a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b131c01ed11a4584ae987ccfb82dc06f",
              "IPY_MODEL_f3faebd429b74c5a8ddbb19f88f4fbec"
            ]
          }
        },
        "a323264e30b44396a15b47a2c52f13a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b131c01ed11a4584ae987ccfb82dc06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b9ae467fcc74c84a4eb0e567fd4b612",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 531456000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 531456000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_431433d5613246dcb088349635a4e89a"
          }
        },
        "f3faebd429b74c5a8ddbb19f88f4fbec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c024ab830a9a45b388df9f385aa1b570",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 507M/507M [02:10&lt;00:00, 4.06MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4965987b8d64bbdb7e1a8d876e0047d"
          }
        },
        "4b9ae467fcc74c84a4eb0e567fd4b612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "431433d5613246dcb088349635a4e89a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c024ab830a9a45b388df9f385aa1b570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4965987b8d64bbdb7e1a8d876e0047d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uv8S6JFWglQ"
      },
      "source": [
        "# Setting TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VwPZnANWkrP"
      },
      "source": [
        "# Make sure to use TPU\n",
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FU4g04oXAK9",
        "outputId": "d33bcfd2-060f-4c44-9fa2-a77c89884555"
      },
      "source": [
        "# Installing PyTorch/XLA\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cloud-tpu-client==0.10\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting torch-xla==1.8.1\n",
            "\u001b[?25l  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl (145.0MB)\n",
            "\u001b[K     |████████████████████████████████| 145.0MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.30.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (20.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (56.1.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "\u001b[31mERROR: earthengine-api 0.1.264 has requirement google-api-python-client<2,>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client, torch-xla\n",
            "  Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0 torch-xla-1.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ien1hOxXO5L",
        "outputId": "803f778c-dd93-40ce-aa0e-d9b2192f4a22"
      },
      "source": [
        "# Import pytorch/xla\n",
        "import torch\n",
        "\n",
        "# imports the torch_xla package\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.8.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWHW2-BlYWDd"
      },
      "source": [
        "# make device\n",
        "device = xm.xla_device()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0Ja5K0tNVQdu"
      },
      "source": [
        "# Train distance via colab\n",
        "## Import Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "E-8yxPmKVQdw"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import h5py\n",
        "import scipy.io\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import json\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "GDJYNuEVVQdx"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oKi5PgogVQdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d434c1-9fb9-4836-8bb5-1064718da8a1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "data_path = 'gdrive/MyDrive/Colab Notebooks/nyu_depth_data_labeled.mat'\n",
        "root_path = 'gdrive/MyDrive/Colab Notebooks/'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LUkb-qKBVQdx"
      },
      "source": [
        "## Define Dataset Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "f8_QkB4zVQdx"
      },
      "source": [
        "class NyDataset(Dataset):\n",
        "    \"\"\"Newyork Data\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None, x_point=10, y_point=10):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string):\n",
        "                모든 이미지가 존재하는 디렉토리 경로\n",
        "            transform (callable, optional):\n",
        "                샘플에 적용될 Optional transform\n",
        "            point (int):\n",
        "                이미즈 한 변의 point 개수\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.img_data_file = h5py.File(root_dir)\n",
        "        self.transform = transform\n",
        "        self.x_point = x_point\n",
        "        self.y_point = y_point\n",
        "        self.point = x_point * y_point\n",
        "\n",
        "        f = h5py.File(self.root_dir)\n",
        "\n",
        "        self.len = f['images'].shape[0]\n",
        "        \n",
        "        # flag for read image from *.mat or raw image.\n",
        "        self.read_img = False\n",
        "        self.read_depth = False\n",
        "        self.X = [None] * self.__len__()\n",
        "        self.depth = [None] * self.__len__()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len * self.point\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        if type(idx) is list:\n",
        "            converted_idx = np.array([(i // self.point, i % self.point) for i in idx])\n",
        "        elif type(idx) is int:\n",
        "            converted_idx = np.array([[idx // self.point, idx % self.point]])\n",
        "            # converted_idx = np.reshape(converted_idx, (converted_idx.shape[0], 1))\n",
        "\n",
        "        image = self.__get_image(self.root_dir, converted_idx[:, 0])\n",
        "        # raw_depth_image = self.__get_raw_depth(self.root_dir, converted_idx[:, 0])\n",
        "\n",
        "        if not self.read_depth:\n",
        "            # Read idx depth image first time\n",
        "            depth_image = self.__get_depth(self.root_dir, converted_idx[:, 0])\n",
        "            depth_list, target_coordinate = self.get_depth_point(converted_idx[:, 1], depth_image=depth_image)\n",
        "        else:\n",
        "            # print('aready read dpeth img')\n",
        "            # Already read idx dpeth image\n",
        "            depth_list, target_coordinate = self.get_depth_point(converted_idx[:, 1])\n",
        "\n",
        "\n",
        "        sample = {\n",
        "            'image': image,\n",
        "            'target_coordinate': target_coordinate\n",
        "        }\n",
        "\n",
        "        return sample, depth_list\n",
        "\n",
        "    def get_depth_point(self, idxes, depth_image=None):\n",
        "        # print(idxes)\n",
        "        if depth_image is None:\n",
        "            return self.depth[idxes[0]]\n",
        "        else:\n",
        "            # Not coordinate of image, only order of training points.\n",
        "            positions = [ [idx % self.point // self.x_point, idx % self.point % self.x_point ] for idx in idxes]\n",
        "            x_interval = depth_image.shape[1] // self.x_point\n",
        "            y_interval = depth_image.shape[2] // self.y_point\n",
        "\n",
        "            depth = [ depth_image[0][pos[0] * x_interval][pos[1] * y_interval] for pos in positions ]\n",
        "            target_coordinate = [ [pos[0] * x_interval, pos[1] * y_interval] for pos in positions ]\n",
        "\n",
        "            depth = np.array(depth)\n",
        "\n",
        "            self.depth[idxes[0]] = [depth, target_coordinate]\n",
        "\n",
        "            return depth, target_coordinate\n",
        "\n",
        "    def __get_raw_depth(self, root_dir, idx):\n",
        "        rawDepth = self.img_data_file['rawDepths'][idx] / 4.0\n",
        "        # return rawDepth\n",
        "        # rawDepth_ = np.empty([480, 640, 3])\n",
        "        # rawDepth_[:, :, 0] = rawDepth[:, :].T\n",
        "        # rawDepth_[:, :, 1] = rawDepth[:, :].T\n",
        "        # rawDepth_[:, :, 2] = rawDepth[:, :].T\n",
        "\n",
        "        # image = io.imread(rawDepth_ / 4.0)\n",
        "        return rawDepth\n",
        "\n",
        "    def __get_depth(self, root_dir, idx):\n",
        "        depth = self.img_data_file['depths'][idx] # (1, 640, 480)\n",
        "        # return depth\n",
        "        # depth_ = np.empty([480, 640, 1])\n",
        "        # depth_[:, :, 0] = depth[:, :].T\n",
        "        # depth_[:, :, 1] = depth[:, :].T\n",
        "        # depth_[:, :, 2] = depth[:, :].T\n",
        "        # depth_ = depth.T\n",
        "\n",
        "        transform_depth = depth.astype('float32') / 4.0\n",
        "        return transform_depth\n",
        "\n",
        "    def __get_image(self, root_dir, idx):\n",
        "        if self.read_img:\n",
        "            # print('aready read img')\n",
        "            return self.X[idx[0]]\n",
        "        else:\n",
        "            img = self.img_data_file['images'][idx][0] # (3, 640, 480)\n",
        "            # return img\n",
        "            # img_ = np.empty([480, 640, 3])\n",
        "            # img_[:, :, 0] = img[0, :, :].T\n",
        "            # img_[:, :, 1] = img[1, :, :].T\n",
        "            # img_[:, :, 2] = img[2, :, :].T\n",
        "\n",
        "            transform_img = img.astype('float32') / 255.0\n",
        "            self.X[idx[0]] = transform_img\n",
        "\n",
        "            return transform_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ReLB0BCIVQdz"
      },
      "source": [
        "## Define Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FAznngR8VQdz"
      },
      "source": [
        "class Data:\n",
        "    def __init__(self, path, test=False):\n",
        "        self.test = test\n",
        "        self.ny_dataset = NyDataset(path)\n",
        "\n",
        "    def get_dataset(self, train_ratio=0.8):\n",
        "        if self.test:\n",
        "            train_len = 100\n",
        "            test_len = 10\n",
        "            train_dataset, test_dataset, _ = torch.utils.data.random_split(self.ny_dataset,\n",
        "                                                                        [train_len, test_len,\n",
        "                                                                         len(self.ny_dataset) - train_len - test_len])\n",
        "\n",
        "            train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "            test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n",
        "        else:\n",
        "            # Set split length\n",
        "            train_len = int(len(self.ny_dataset) * train_ratio)\n",
        "            test_len = len(self.ny_dataset) - train_len\n",
        "\n",
        "            train_dataset, test_dataset = torch.utils.data.random_split(self.ny_dataset, [train_len, test_len])\n",
        "\n",
        "            train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=3, shuffle=True)\n",
        "            test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=3, shuffle=True)\n",
        "\n",
        "        return train_loader, test_loader\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VTAfFx0GVQdz"
      },
      "source": [
        "## Define MIS model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8gQqGLtwVQd0"
      },
      "source": [
        "class MIS(nn.Module):\n",
        "    \"\"\"Measuring Image Distance Model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sub_sampling_ratio=16, width=480, height=640, model_selection='mobile'):\n",
        "        super(MIS, self).__init__()\n",
        "        self.sub_sampling_ratio = sub_sampling_ratio\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.model_selection = model_selection\n",
        "\n",
        "        size = (7, 7)\n",
        "        fc1_out = 64\n",
        "        fc2_out = int(fc1_out / 4)\n",
        "\n",
        "        self.feature_extractor = self.get_feature_extraction()\n",
        "        self.adaptive_max_pool = nn.AdaptiveMaxPool2d(size)\n",
        "        self.fc1 = nn.Linear(7 * 7 * self.extraction_size + 2, fc1_out)\n",
        "        self.fc2 = nn.Linear(fc1_out, fc2_out)\n",
        "        self.fc3 = nn.Linear(fc2_out, 1)\n",
        "        self.dropout = nn.Dropout(p=0.7)\n",
        "\n",
        "        print('make MIS model')\n",
        "\n",
        "    def rol_pooling(self, output_map):\n",
        "        output = [self.adaptive_max_pool(out)[0] for out in output_map]\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, sample):\n",
        "        x = sample[0] # image\n",
        "        target = sample[1] # target coordinate\n",
        "\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.adaptive_max_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        targetT = torch.transpose(target, 0, 1)\n",
        "\n",
        "        x_list = x.tolist()\n",
        "        targetT_list = targetT.tolist()\n",
        "\n",
        "        for i in range(x.shape[0]):\n",
        "            for target in targetT_list[i]:\n",
        "                x_list[i].append(target)\n",
        "        x = torch.tensor(x_list).cuda()\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        # x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        # x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        # output = F.softplus(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_feature_extraction(self):\n",
        "        \"\"\"Return network which produces feature map.\n",
        "        \"\"\"\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        if self.model_selection == 'vgg':\n",
        "            model = torchvision.models.vgg11(pretrained=True).to(device)\n",
        "            self.extraction_size = 512\n",
        "        elif self.model_selection == 'mobile':\n",
        "            model = torchvision.models.mobilenet_v3_small(pretrained=True).to(device)\n",
        "            self.extraction_size = 48\n",
        "\n",
        "        features = list(model.features)\n",
        "\n",
        "        # only collect layers with output feature map size (W, H) < 50\n",
        "        dummy_img = torch.zeros((1, 3, self.width, self.height)).float()  # test image array\n",
        "\n",
        "        req_features = []\n",
        "        output = dummy_img.clone().to(device)\n",
        "\n",
        "        for feature in features:\n",
        "            output = feature(output)\n",
        "            #     print(output.size()) => torch.Size([batch_size, channel, width, height])\n",
        "\n",
        "            # If size of convolution result is threshold, break.\n",
        "            if output.size()[2] < self.width // self.sub_sampling_ratio \\\n",
        "                    and output.size()[3] < self.height // self.sub_sampling_ratio:\n",
        "                break\n",
        "            req_features.append(feature)\n",
        "\n",
        "        faster_rcnn_feature_extractor = nn.Sequential(*req_features)\n",
        "        return faster_rcnn_feature_extractor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6qniv5YTVQd0"
      },
      "source": [
        "## Define train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qQmqsehFVQd0"
      },
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    \"\"\"Calculate RMSE Loss for validating test data.\n",
        "    \"\"\"\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, yhat, y):\n",
        "        \"\"\"Calculate RMSE Loss from two vectors.\n",
        "        Plus epsilon for preventing zero division.\n",
        "        \"\"\"\n",
        "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
        "        return loss\n",
        "\n",
        "class Train:\n",
        "    def __init__(self):\n",
        "        self.save_path = 'gdrive/MyDrive/Colab Notebooks/'\n",
        "\n",
        "    def train(self, data):\n",
        "        train_loader, test_loader = data\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # torch.manual_seed(53)\n",
        "        # if device == 'cuda':\n",
        "        #     torch.cuda.manual_seed_all(53)\n",
        "\n",
        "        model = MIS(model_selection='vgg')\n",
        "\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1, 2, 3'\n",
        "            model = nn.DataParallel(model, output_device=1)\n",
        "            print('Multi GPU!!!!!!!!!!!!!!')\n",
        "\n",
        "        model = model.to(device)\n",
        "        model.train()\n",
        "\n",
        "        # Optimize\n",
        "        # criterion = nn.CrossEntropyLoss().cuda()\n",
        "        criterion = nn.SmoothL1Loss().cuda()\n",
        "        # optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
        "        epochs = 20\n",
        "\n",
        "        import time\n",
        "        start_time = time.time()\n",
        "        min_loss = int(1e9)\n",
        "        history = {'loss': [], 'val_acc': []}\n",
        "        for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "            epoch_loss = 0.0\n",
        "            tk0 = tqdm(train_loader, total=len(train_loader), leave=False)\n",
        "            for step, (inputs, labels) in enumerate(tk0, 0):\n",
        "                image_inputs = inputs['image']\n",
        "                coordinate_inputs = torch.stack([val for val in inputs['target_coordinate'][0]], dim=0).to(device)\n",
        "                image_inputs, labels = image_inputs.to(device), labels.to(device)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model((image_inputs, coordinate_inputs))\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            train_loader.dataset.dataset.read_img = True\n",
        "            train_loader.dataset.dataset.read_depth = True\n",
        "            # print('Make True')\n",
        "\n",
        "            rmse_loss = 0\n",
        "            # validation\n",
        "            # if epoch % 5 == 0:\n",
        "            validation_criterion = RMSELoss()\n",
        "            with torch.no_grad():\n",
        "                for data in test_loader:\n",
        "                    inputs, labels = data\n",
        "                    image_inputs = inputs['image']\n",
        "                    coordinate_inputs = torch.stack([val for val in inputs['target_coordinate'][0]], dim=0).cuda()\n",
        "\n",
        "                    images = image_inputs.cuda()\n",
        "                    labels = labels.cuda()\n",
        "                    outputs = model((images, coordinate_inputs))\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    rmse_loss = validation_criterion(labels, predicted)\n",
        "\n",
        "            # print statistics\n",
        "            tqdm.write('[Epoch : %d] train_loss: %.5f va rmse loss: %.5f Total_elapsed_time: %d minute' %\n",
        "                       (epoch + 1, epoch_loss / len(train_loader), rmse_loss, (time.time() - start_time) / 60))\n",
        "            history['loss'].append(epoch_loss / len(train_loader))\n",
        "            history['val_acc'].append(rmse_loss)\n",
        "\n",
        "            # if epoch in [36, 64, 92]:\n",
        "            #     for g in optimizer.param_groups:\n",
        "            #         g['lr'] /= 10\n",
        "            #     print('Loss 1/10')\n",
        "\n",
        "        print((time.time() - start_time) / 60)\n",
        "        print('Finished Training')\n",
        "\n",
        "        model_name = f'mobilenet-epoch-{epcoh}-model_state_dict.pth'\n",
        "        torch.save(model.state_dict(), os.path.join(self.save_path, model_name))\n",
        "        print('save model as', model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Njx8KARvVQd1"
      },
      "source": [
        "# Load Data and Run trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wnAxuq9mVQd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480,
          "referenced_widgets": [
            "8147facf455a4ef0abc520b53421ea31",
            "45ec6d6ea6bc43acb3dad166b046aed9",
            "f5bc69776dee47a4a2c2b3cfce2a7519",
            "35e8a20e4a1141cdbebc6c6ebb513892",
            "3b325efb1bb34364b672a5c4e0a7d98d",
            "6baab9ebb6344bb59eba1fab015ef8a2",
            "ab04ed14d9204dd1a4d41f643880d777",
            "068cb2b7963b49dc9ec3edb9bc2bc365"
          ]
        },
        "outputId": "7e7097f3-b768-4feb-e7f0-b2e5cdd15616"
      },
      "source": [
        "dataset = Data(data_path)\n",
        "train_data = dataset.get_dataset()\n",
        "\n",
        "trainer = Train()\n",
        "trainer.train(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make MIS model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8147facf455a4ef0abc520b53421ea31",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=60907.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5c153b075656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-2d7101b2427b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mtk0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtk0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mimage_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mcoordinate_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_coordinate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5ee2366ae324>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Read idx depth image first time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdepth_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mdepth_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_coordinate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_depth_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5ee2366ae324>\u001b[0m in \u001b[0;36m__get_depth\u001b[0;34m(self, root_dir, idx)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_data_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'depths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (1, 640, 480)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;31m# return depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# depth_ = np.empty([480, 640, 1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn9k9_S2AGsc"
      },
      "source": [
        "# Load model and Predict\n",
        "\n",
        "## Define depth predictor class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWfvQ-0wAKr4"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class DistancePredictor:\n",
        "    def __init__(self, model_path, model_selection):\n",
        "        state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "        self.model = MIS(model_selection=model_selection)\n",
        "        self.model.load_state_dict(state_dict)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def predict(self, image, point):\n",
        "        self.model.eval()\n",
        "        self.model = self.model.to(self.device)\n",
        "\n",
        "        image = np.reshape(image, (1, 3, 640, 480))\n",
        "        image = torch.tensor(image).to(self.device)\n",
        "\n",
        "        point = [torch.tensor([point[0]]), torch.tensor([point[1]])]\n",
        "        point = torch.tensor(point)\n",
        "        point = torch.reshape(point, (2, 1))\n",
        "\n",
        "        output = self.model((image, point))\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuCJLh4aAvMo"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K90y_vb5AX36"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "e3652d9ff48f4ba88c2f5ef5eef6e7a1",
            "a323264e30b44396a15b47a2c52f13a0",
            "b131c01ed11a4584ae987ccfb82dc06f",
            "f3faebd429b74c5a8ddbb19f88f4fbec",
            "4b9ae467fcc74c84a4eb0e567fd4b612",
            "431433d5613246dcb088349635a4e89a",
            "c024ab830a9a45b388df9f385aa1b570",
            "d4965987b8d64bbdb7e1a8d876e0047d"
          ]
        },
        "id": "3BDXqLlBA3c6",
        "outputId": "68daf140-2b65-4b1d-9dc1-44cf49d7d694"
      },
      "source": [
        "model_name = 'model_state_dict.pth'\n",
        "model_path = os.path.join(root_path, model_name)\n",
        "predictor = DistancePredictor(model_path, 'vgg')\n",
        "\n",
        "path_to_depth_v1 = 'gdrive/MyDrive/Colab Notebooks/nyu_depth_data_labeled.mat'\n",
        "f = h5py.File(path_to_depth_v1)\n",
        "img = f['images'][0]\n",
        "transform_img = img.astype('float32') / 255.0\n",
        "\n",
        "depth = f['depths'][0]\n",
        "\n",
        "for point in range(5):\n",
        "    target = [640 // 10 * point, 480 // 10 * point]\n",
        "    output = predictor.predict(transform_img, target)\n",
        "    print('real depth =', depth[target[0]][target[1]], 'predict depth =', output.item() * 4)\n",
        "\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg11-bbd30ac9.pth\" to /root/.cache/torch/hub/checkpoints/vgg11-bbd30ac9.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3652d9ff48f4ba88c2f5ef5eef6e7a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=531456000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "make MIS model\n",
            "real depth = 2.7144513 predict depth = 3.0197579860687256\n",
            "real depth = 2.7144513 predict depth = 3.0197579860687256\n",
            "\n",
            "real depth = 2.7544267 predict depth = 3.0509114265441895\n",
            "real depth = 2.692155 predict depth = 3.064953565597534\n",
            "\n",
            "real depth = 3.039136 predict depth = 3.082064628601074\n",
            "real depth = 3.0115318 predict depth = 3.1101491451263428\n",
            "\n",
            "real depth = 3.1535077 predict depth = 3.113218069076538\n",
            "real depth = 3.0720863 predict depth = 3.1553447246551514\n",
            "\n",
            "real depth = 3.2476234 predict depth = 3.144371271133423\n",
            "real depth = 3.1464646 predict depth = 3.20054030418396\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}